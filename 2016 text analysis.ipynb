{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from glob import glob\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "ohco = ['speech_id','speaker','para_id','sent_id','token_id']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_json('data/ucsb_speeches_2016.json')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>link</th>\n",
       "      <th>title</th>\n",
       "      <th>date</th>\n",
       "      <th>person</th>\n",
       "      <th>transcript</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>/documents/remarks-town-hall-meeting-portsmout...</td>\n",
       "      <td>Remarks at a Town Hall Meeting in Portsmouth, ...</td>\n",
       "      <td>2015-12-29 00:00:00+00:00</td>\n",
       "      <td>Hillary Clinton</td>\n",
       "      <td>\\nCLINTON: Wow. Thank you. Thank you all. Than...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>/documents/remarks-the-university-minnesota-mi...</td>\n",
       "      <td>Remarks at the University of Minnesota in Minn...</td>\n",
       "      <td>2015-12-15 00:00:00+00:00</td>\n",
       "      <td>Hillary Clinton</td>\n",
       "      <td>\\nThank you. Thank you all very much. Thank yo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>/documents/interview-with-george-stephanopoulo...</td>\n",
       "      <td>Interview with George Stephanopoulos of ABC Ne...</td>\n",
       "      <td>2015-12-06 00:00:00+00:00</td>\n",
       "      <td>Hillary Clinton</td>\n",
       "      <td>\\nSTEPHANOPOULOS: And we'll hear more on that ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>/documents/interview-with-charlie-rose</td>\n",
       "      <td>Interview with Charlie Rose</td>\n",
       "      <td>2015-12-01 00:00:00+00:00</td>\n",
       "      <td>Hillary Clinton</td>\n",
       "      <td>\\nROSE: She is a former first lady, a former s...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>/documents/remarks-and-question-and-answer-ses...</td>\n",
       "      <td>Remarks and a Question and Answer Session at t...</td>\n",
       "      <td>2015-11-19 00:00:00+00:00</td>\n",
       "      <td>Hillary Clinton</td>\n",
       "      <td>\\nCLINTON: Thank you. Thank you very much. [ap...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                link  \\\n",
       "0  /documents/remarks-town-hall-meeting-portsmout...   \n",
       "1  /documents/remarks-the-university-minnesota-mi...   \n",
       "2  /documents/interview-with-george-stephanopoulo...   \n",
       "3             /documents/interview-with-charlie-rose   \n",
       "4  /documents/remarks-and-question-and-answer-ses...   \n",
       "\n",
       "                                               title  \\\n",
       "0  Remarks at a Town Hall Meeting in Portsmouth, ...   \n",
       "1  Remarks at the University of Minnesota in Minn...   \n",
       "2  Interview with George Stephanopoulos of ABC Ne...   \n",
       "3                        Interview with Charlie Rose   \n",
       "4  Remarks and a Question and Answer Session at t...   \n",
       "\n",
       "                       date           person  \\\n",
       "0 2015-12-29 00:00:00+00:00  Hillary Clinton   \n",
       "1 2015-12-15 00:00:00+00:00  Hillary Clinton   \n",
       "2 2015-12-06 00:00:00+00:00  Hillary Clinton   \n",
       "3 2015-12-01 00:00:00+00:00  Hillary Clinton   \n",
       "4 2015-11-19 00:00:00+00:00  Hillary Clinton   \n",
       "\n",
       "                                          transcript  \n",
       "0  \\nCLINTON: Wow. Thank you. Thank you all. Than...  \n",
       "1  \\nThank you. Thank you all very much. Thank yo...  \n",
       "2  \\nSTEPHANOPOULOS: And we'll hear more on that ...  \n",
       "3  \\nROSE: She is a former first lady, a former s...  \n",
       "4  \\nCLINTON: Thank you. Thank you very much. [ap...  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.index.name = 'speech_id'\n",
    "library = df[['link','title','date','person']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# first OHCO level - split out speakers, using e.g. \"CLINTON:\"\n",
    "# set default speaker for each speech - we'll set the specific ones later.\n",
    "df['speaker'] = [x[1] for x in df['person'].str.upper().str.rsplit(' ',1)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.reset_index().set_index(['speech_id','speaker'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# second OHCO level - split out paragraphs, using \"\\n\" as the separator (for these transcripts). \n",
    "# Remove initial/trailing whitespace, including \\n\n",
    "df = df['transcript'].str.strip().str.split(\"\\n\", expand=True)\\\n",
    "    .stack().to_frame().rename(columns={0:'para_str'})\n",
    "df.index.names = ohco[0:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.reset_index().set_index(['speech_id','para_id'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# whenever a paragraph starts with a caps name e.g. CLINTON:\n",
    "# use that as the speaker until the next caps name\n",
    "df['speaker'] = df['para_str'].str.extract(r'([A-Z]+)(:)')[0].ffill()\n",
    "# remove the non-Trump/Clinton speakers\n",
    "df = df[df['speaker'].isin(['TRUMP','CLINTON'])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.reset_index().set_index(ohco[0:3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# remove the caps names\n",
    "df['para_str'] = df['para_str'].str.replace(r'[A-Z]+: ','')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# third ohco level - sentence\n",
    "\n",
    "# Alvarado used NLTK sentence tokenizer to split sentences. \n",
    "# but let's try it the lazy way to start\n",
    "df = df['para_str'].str.split(\"[.!?]+\", expand=True)\\\n",
    "    .stack().to_frame().rename(columns={0:'sent_str'})\n",
    "df.index.names = ohco[0:4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# drop 0-length strings (usually at end of paragraph)\n",
    "df = df[df['sent_str'].str.len() > 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>sent_str</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>speech_id</th>\n",
       "      <th>speaker</th>\n",
       "      <th>para_id</th>\n",
       "      <th>sent_id</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"5\" valign=\"top\">0</th>\n",
       "      <th rowspan=\"5\" valign=\"top\">CLINTON</th>\n",
       "      <th rowspan=\"5\" valign=\"top\">0</th>\n",
       "      <th>0</th>\n",
       "      <td>Wow</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Thank you</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Thank you all</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Thank you</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>I am really delighted to be here on the first...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                            sent_str\n",
       "speech_id speaker para_id sent_id                                                   \n",
       "0         CLINTON 0       0                                                      Wow\n",
       "                          1                                                Thank you\n",
       "                          2                                            Thank you all\n",
       "                          3                                                Thank you\n",
       "                          4         I am really delighted to be here on the first..."
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fourth ohco level - tokens\n",
    "import nltk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/maxwell/opt/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:1: DeprecationWarning: The default dtype for empty Series will be 'object' instead of 'float64' in a future version. Specify a dtype explicitly to silence this warning.\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n"
     ]
    }
   ],
   "source": [
    "token = df['sent_str'].apply(lambda x: pd.Series(nltk.pos_tag(nltk.WhitespaceTokenizer().tokenize(x))))\\\n",
    "    .stack().to_frame()\\\n",
    "    .rename(columns={0:'pos_tuple'})\n",
    "token['pos'] = token.pos_tuple.apply(lambda x: x[1])\n",
    "token['token_str'] = token.pos_tuple.apply(lambda x: x[0])\n",
    "token = token.drop('pos_tuple', 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "token.index.names = ohco # ok, all done"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>pos</th>\n",
       "      <th>token_str</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>speech_id</th>\n",
       "      <th>speaker</th>\n",
       "      <th>para_id</th>\n",
       "      <th>sent_id</th>\n",
       "      <th>token_id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"5\" valign=\"top\">0</th>\n",
       "      <th rowspan=\"5\" valign=\"top\">CLINTON</th>\n",
       "      <th rowspan=\"5\" valign=\"top\">0</th>\n",
       "      <th>0</th>\n",
       "      <th>0</th>\n",
       "      <td>NN</td>\n",
       "      <td>Wow</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">1</th>\n",
       "      <th>0</th>\n",
       "      <td>NN</td>\n",
       "      <td>Thank</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>PRP</td>\n",
       "      <td>you</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">2</th>\n",
       "      <th>0</th>\n",
       "      <td>NNP</td>\n",
       "      <td>Thank</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>PRP</td>\n",
       "      <td>you</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            pos token_str\n",
       "speech_id speaker para_id sent_id token_id               \n",
       "0         CLINTON 0       0       0          NN       Wow\n",
       "                          1       0          NN     Thank\n",
       "                                  1         PRP       you\n",
       "                          2       0         NNP     Thank\n",
       "                                  1         PRP       you"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "token.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lowercase, remove non-word characters\n",
    "token['term_str'] = token['token_str'].str.lower().str.replace('[\\W_]', '')\n",
    "# drop words which consist entirely of non-word characters\n",
    "token = token[token.term_str!=''].sort_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Checkpoint\n",
    "token.to_parquet('data/token.parquet')\n",
    "library.to_parquet('data/library.parquet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load from checkpoint\n",
    "if 'token' not in locals():\n",
    "    token = pd.read_parquet('data/token.parquet')\n",
    "if 'library' not in locals():\n",
    "    library = pd.read_parquet('data/library.parquet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create vocab table\n",
    "# \n",
    "vocab = token.term_str.value_counts().to_frame().rename(columns={'index':'term_str', 'term_str':'n'})\\\n",
    "    .sort_index().reset_index().rename(columns={'index':'term_str'})\n",
    "vocab.index.name = 'term_id'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "# add stopwords\n",
    "vocab['stop'] = 0\n",
    "vocab.loc[vocab['term_str'].isin(nltk.corpus.stopwords.words('english')),'stop'] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "# (optional) add stems\n",
    "#from nltk.stem.porter import PorterStemmer\n",
    "#stemmer = PorterStemmer()\n",
    "#vocab['p_stem'] = vocab.term_str.apply(stemmer.stem)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "# add term rank \n",
    "if 'term_rank' not in vocab.columns:\n",
    "    vocab = vocab.sort_values('n', ascending=False).reset_index()\n",
    "    vocab.index.name = 'term_rank'\n",
    "    vocab = vocab.reset_index().set_index('term_id')\n",
    "    vocab['term_rank'] = vocab['term_rank'] + 1 # start with 1 instead of 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>term_rank</th>\n",
       "      <th>term_str</th>\n",
       "      <th>n</th>\n",
       "      <th>stop</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>term_id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>10832</th>\n",
       "      <td>1</td>\n",
       "      <td>the</td>\n",
       "      <td>13552</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11006</th>\n",
       "      <td>2</td>\n",
       "      <td>to</td>\n",
       "      <td>12704</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>782</th>\n",
       "      <td>3</td>\n",
       "      <td>and</td>\n",
       "      <td>12178</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5499</th>\n",
       "      <td>4</td>\n",
       "      <td>i</td>\n",
       "      <td>7337</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7517</th>\n",
       "      <td>5</td>\n",
       "      <td>of</td>\n",
       "      <td>6918</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         term_rank term_str      n  stop\n",
       "term_id                                 \n",
       "10832            1      the  13552     1\n",
       "11006            2       to  12704     1\n",
       "782              3      and  12178     1\n",
       "5499             4        i   7337     1\n",
       "7517             5       of   6918     1"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vocab.sort_values('n', ascending=False).head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "# add term id back to token table, for easy joining\n",
    "token['term_id'] = token.term_str.map(vocab.reset_index().set_index('term_str').term_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Checkpoint\n",
    "vocab.to_parquet('data/vocab.parquet')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create DT matrices \n",
    "(Document-Term matrix, using Bag of Words and TF-IDF)\n",
    "\n",
    "One each for Trump and Clinton"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load from checkpoint\n",
    "if 'vocab' not in locals():\n",
    "    vocab = pd.read_parquet('data/vocab.parquet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "bag = ohco[:1] # bag size = 1 speech"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "# identify stopwords\n",
    "token['stop'] = 0\n",
    "token.loc[token['term_str'].isin(nltk.corpus.stopwords.words('english')),'stop'] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "#remove stopwords\n",
    "token=token[token.stop==0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 100 speeches, take 20% for test set\n",
    "test_ids = np.random.choice(token.reset_index().speech_id.unique(),size=20,replace=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "token = token.reset_index().set_index('speech_id')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_token = token.loc[test_ids]\n",
    "train_token = token.loc[~token.index.isin(test_ids)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split into Trump/Clinton\n",
    "clinton_train = train_token.query('speaker==\"CLINTON\"')\n",
    "trump_train = train_token.query('speaker==\"TRUMP\"')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.48148148148148145, 0.5185185185185185]"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clinton_count = len(clinton_train.index.unique())\n",
    "trump_count = len(trump_train.index.unique())\n",
    "total_count = clinton_count + trump_count\n",
    "priors = [clinton_count/total_count,trump_count/total_count]\n",
    "priors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_vocab(token, a=1):\n",
    "    vocab = token.term_str.value_counts().to_frame().rename(columns={'index':'term_str', 'term_str':'n'})\\\n",
    "    .sort_index().reset_index().rename(columns={'index':'term_str'})\n",
    "    vocab.index.name = 'term_id'\n",
    "    vocab['stop'] = 0\n",
    "    vocab.loc[vocab['term_str'].isin(nltk.corpus.stopwords.words('english')),'stop'] = 1\n",
    "    if 'term_rank' not in vocab.columns:\n",
    "        vocab = vocab.sort_values('n', ascending=False).reset_index()\n",
    "        vocab.index.name = 'term_rank'\n",
    "        vocab = vocab.reset_index().set_index('term_id')\n",
    "        vocab['term_rank'] = vocab['term_rank'] + 1 # start with 1 instead of 0\n",
    "    token['term_id'] = token.term_str.map(vocab.reset_index().set_index('term_str').term_id)\n",
    "    BOW = token.groupby(bag+['term_id']).term_id.count()\\\n",
    "    .to_frame().rename(columns={'term_id':'n'})\n",
    "    DTCM = BOW['n'].unstack().fillna(0).astype('int')\n",
    "    # Term frequency - normalized\n",
    "    TF = (DTCM.T / DTCM.T.sum()).T\n",
    "    DF = DTCM[DTCM > 0].count()\n",
    "    freq=TF.sum().reset_index()\n",
    "    #freq=DTCM.sum().reset_index() #optional to get more variance in the likelihood\n",
    "    vocab['freq'] = freq[0]\n",
    "    tf = vocab.freq # term frequency (normalized)\n",
    "    N = vocab.freq.sum() # sum of all term frequencies in this class\n",
    "    V = vocab.shape[0] # vocab size\n",
    "    # https://stackoverflow.com/questions/3704570/in-python-small-floats-tending-to-zero\n",
    "    # https://nlp.stanford.edu/IR-book/html/htmledition/naive-bayes-text-classification-1.html\n",
    "    # using the log likelihood for these reasons\n",
    "    vocab['likelihood'] = np.log((tf+a) / (N+ a*V))\n",
    "    vocab.sort_values('likelihood',ascending=False)\n",
    "    return vocab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/maxwell/opt/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:12: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  if sys.path[0] == '':\n"
     ]
    }
   ],
   "source": [
    "vocab_c = create_vocab(clinton_train).reset_index().set_index('term_str')\n",
    "vocab_t = create_vocab(trump_train).reset_index().set_index('term_str')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "def NB_classifier(token_test, class1_vocab, class2_vocab, class_1_name = 'Class 1', class_2_name = 'Class 2', priors=[.5,.5]):\n",
    "    d = {'speech_id': token_test.index.unique(), 'true_value': \"\", 'prediction': \"\"}\n",
    "    results = pd.DataFrame(d).set_index('speech_id')\n",
    "    \n",
    "    for i in results.index:\n",
    "        results['true_value'].loc[i] = test_token.at[i,'speaker'][0]\n",
    "        \n",
    "        speech = token_test.loc[i]\n",
    "        \n",
    "        speech = speech.merge(class1_vocab['likelihood'], how='left', on=\"term_str\")\\\n",
    "        .rename(columns={'likelihood': class_1_name})\n",
    "        speech = speech.merge(class2_vocab['likelihood'], how='left', on=\"term_str\")\\\n",
    "        .rename(columns={'likelihood': class_2_name})\n",
    "        \n",
    "        predict = pd.DataFrame(speech[[class_1_name,class_2_name]].sum())\n",
    "        logpriors = np.log(priors)\n",
    "        predict[0] = predict[0] + logpriors\n",
    "        predict = predict.sort_values(by=0, ascending=False)\n",
    "        classification = predict.index[0]\n",
    "        \n",
    "        results['prediction'].loc[i] = classification\n",
    "        \n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>true_value</th>\n",
       "      <th>prediction</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>speech_id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>139</th>\n",
       "      <td>TRUMP</td>\n",
       "      <td>CLINTON</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>TRUMP</td>\n",
       "      <td>CLINTON</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>CLINTON</td>\n",
       "      <td>CLINTON</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>TRUMP</td>\n",
       "      <td>CLINTON</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>TRUMP</td>\n",
       "      <td>CLINTON</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>CLINTON</td>\n",
       "      <td>TRUMP</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>162</th>\n",
       "      <td>CLINTON</td>\n",
       "      <td>TRUMP</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>CLINTON</td>\n",
       "      <td>CLINTON</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>137</th>\n",
       "      <td>TRUMP</td>\n",
       "      <td>CLINTON</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>TRUMP</td>\n",
       "      <td>CLINTON</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>59</th>\n",
       "      <td>CLINTON</td>\n",
       "      <td>CLINTON</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>161</th>\n",
       "      <td>CLINTON</td>\n",
       "      <td>TRUMP</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>117</th>\n",
       "      <td>TRUMP</td>\n",
       "      <td>CLINTON</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>CLINTON</td>\n",
       "      <td>CLINTON</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>146</th>\n",
       "      <td>CLINTON</td>\n",
       "      <td>TRUMP</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>120</th>\n",
       "      <td>TRUMP</td>\n",
       "      <td>CLINTON</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>126</th>\n",
       "      <td>TRUMP</td>\n",
       "      <td>CLINTON</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>152</th>\n",
       "      <td>CLINTON</td>\n",
       "      <td>TRUMP</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>138</th>\n",
       "      <td>TRUMP</td>\n",
       "      <td>CLINTON</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>156</th>\n",
       "      <td>CLINTON</td>\n",
       "      <td>TRUMP</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          true_value prediction\n",
       "speech_id                      \n",
       "139            TRUMP    CLINTON\n",
       "39             TRUMP    CLINTON\n",
       "12           CLINTON    CLINTON\n",
       "40             TRUMP    CLINTON\n",
       "32             TRUMP    CLINTON\n",
       "11           CLINTON      TRUMP\n",
       "162          CLINTON      TRUMP\n",
       "31           CLINTON    CLINTON\n",
       "137            TRUMP    CLINTON\n",
       "46             TRUMP    CLINTON\n",
       "59           CLINTON    CLINTON\n",
       "161          CLINTON      TRUMP\n",
       "117            TRUMP    CLINTON\n",
       "5            CLINTON    CLINTON\n",
       "146          CLINTON      TRUMP\n",
       "120            TRUMP    CLINTON\n",
       "126            TRUMP    CLINTON\n",
       "152          CLINTON      TRUMP\n",
       "138            TRUMP    CLINTON\n",
       "156          CLINTON      TRUMP"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# class 1 is clinton, class 2 is trump\n",
    "\n",
    "results=NB_classifier(test_token,vocab_c,vocab_t, class_1_name = 'CLINTON', class_2_name = 'TRUMP', priors=priors)\n",
    "results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 4,  6],\n",
       "       [10,  0]])"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "confusion_matrix(results.true_value, results.prediction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [],
   "source": [
    "speech = test_token.loc[44]\n",
    "        \n",
    "speech = speech.merge(vocab_c['likelihood'], how='left', on=\"term_str\")\\\n",
    "        .rename(columns={'likelihood': 'clinton'})\n",
    "speech = speech.merge(vocab_t['likelihood'], how='left', on=\"term_str\")\\\n",
    "        .rename(columns={'likelihood': 'trump'})\n",
    "        \n",
    "predict = pd.DataFrame(speech[['clinton','trump']].sum())\n",
    "logpriors = np.log(priors)\n",
    "predict[0] = predict[0] + logpriors\n",
    "predict = predict.sort_values(by=0, ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>clinton</th>\n",
       "      <td>-13730.913300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>trump</th>\n",
       "      <td>-13919.136719</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    0\n",
       "clinton -13730.913300\n",
       "trump   -13919.136719"
      ]
     },
     "execution_count": 137,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
