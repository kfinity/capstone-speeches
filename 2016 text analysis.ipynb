{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 226,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from glob import glob\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 227,
   "metadata": {},
   "outputs": [],
   "source": [
    "ohco = ['speech_id','speaker','para_id','sent_id','token_id']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 228,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_json('data/ucsb_speeches_2016.json')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 229,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>link</th>\n",
       "      <th>title</th>\n",
       "      <th>date</th>\n",
       "      <th>person</th>\n",
       "      <th>transcript</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>/documents/remarks-town-hall-meeting-portsmout...</td>\n",
       "      <td>Remarks at a Town Hall Meeting in Portsmouth, ...</td>\n",
       "      <td>2015-12-29 00:00:00+00:00</td>\n",
       "      <td>Hillary Clinton</td>\n",
       "      <td>\\nCLINTON: Wow. Thank you. Thank you all. Than...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>/documents/remarks-the-university-minnesota-mi...</td>\n",
       "      <td>Remarks at the University of Minnesota in Minn...</td>\n",
       "      <td>2015-12-15 00:00:00+00:00</td>\n",
       "      <td>Hillary Clinton</td>\n",
       "      <td>\\nThank you. Thank you all very much. Thank yo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>/documents/interview-with-george-stephanopoulo...</td>\n",
       "      <td>Interview with George Stephanopoulos of ABC Ne...</td>\n",
       "      <td>2015-12-06 00:00:00+00:00</td>\n",
       "      <td>Hillary Clinton</td>\n",
       "      <td>\\nSTEPHANOPOULOS: And we'll hear more on that ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>/documents/interview-with-charlie-rose</td>\n",
       "      <td>Interview with Charlie Rose</td>\n",
       "      <td>2015-12-01 00:00:00+00:00</td>\n",
       "      <td>Hillary Clinton</td>\n",
       "      <td>\\nROSE: She is a former first lady, a former s...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>/documents/remarks-and-question-and-answer-ses...</td>\n",
       "      <td>Remarks and a Question and Answer Session at t...</td>\n",
       "      <td>2015-11-19 00:00:00+00:00</td>\n",
       "      <td>Hillary Clinton</td>\n",
       "      <td>\\nCLINTON: Thank you. Thank you very much. [ap...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                link  \\\n",
       "0  /documents/remarks-town-hall-meeting-portsmout...   \n",
       "1  /documents/remarks-the-university-minnesota-mi...   \n",
       "2  /documents/interview-with-george-stephanopoulo...   \n",
       "3             /documents/interview-with-charlie-rose   \n",
       "4  /documents/remarks-and-question-and-answer-ses...   \n",
       "\n",
       "                                               title  \\\n",
       "0  Remarks at a Town Hall Meeting in Portsmouth, ...   \n",
       "1  Remarks at the University of Minnesota in Minn...   \n",
       "2  Interview with George Stephanopoulos of ABC Ne...   \n",
       "3                        Interview with Charlie Rose   \n",
       "4  Remarks and a Question and Answer Session at t...   \n",
       "\n",
       "                       date           person  \\\n",
       "0 2015-12-29 00:00:00+00:00  Hillary Clinton   \n",
       "1 2015-12-15 00:00:00+00:00  Hillary Clinton   \n",
       "2 2015-12-06 00:00:00+00:00  Hillary Clinton   \n",
       "3 2015-12-01 00:00:00+00:00  Hillary Clinton   \n",
       "4 2015-11-19 00:00:00+00:00  Hillary Clinton   \n",
       "\n",
       "                                          transcript  \n",
       "0  \\nCLINTON: Wow. Thank you. Thank you all. Than...  \n",
       "1  \\nThank you. Thank you all very much. Thank yo...  \n",
       "2  \\nSTEPHANOPOULOS: And we'll hear more on that ...  \n",
       "3  \\nROSE: She is a former first lady, a former s...  \n",
       "4  \\nCLINTON: Thank you. Thank you very much. [ap...  "
      ]
     },
     "execution_count": 229,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 230,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.index.name = 'speech_id'\n",
    "library = df[['link','title','date','person']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 231,
   "metadata": {},
   "outputs": [],
   "source": [
    "# first OHCO level - split out speakers, using e.g. \"CLINTON:\"\n",
    "# set default speaker for each speech - we'll set the specific ones later.\n",
    "df['speaker'] = [x[1] for x in df['person'].str.upper().str.rsplit(' ',1)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 232,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.reset_index().set_index(['speech_id','speaker'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 233,
   "metadata": {},
   "outputs": [],
   "source": [
    "# second OHCO level - split out paragraphs, using \"\\n\" as the separator (for these transcripts). \n",
    "# Remove initial/trailing whitespace, including \\n\n",
    "df = df['transcript'].str.strip().str.split(\"\\n\", expand=True)\\\n",
    "    .stack().to_frame().rename(columns={0:'para_str'})\n",
    "df.index.names = ohco[0:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 234,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.reset_index().set_index(['speech_id','para_id'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 235,
   "metadata": {},
   "outputs": [],
   "source": [
    "# whenever a paragraph starts with a caps name e.g. CLINTON:\n",
    "# use that as the speaker until the next caps name\n",
    "df['speaker'] = df['para_str'].str.extract(r'([A-Z]+)(:)')[0].ffill()\n",
    "# remove the non-Trump/Clinton speakers\n",
    "df = df[df['speaker'].isin(['TRUMP','CLINTON'])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 236,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.reset_index().set_index(ohco[0:3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 237,
   "metadata": {},
   "outputs": [],
   "source": [
    "# remove the caps names\n",
    "df['para_str'] = df['para_str'].str.replace(r'[A-Z]+: ','')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 238,
   "metadata": {},
   "outputs": [],
   "source": [
    "# third ohco level - sentence\n",
    "\n",
    "# Alvarado used NLTK sentence tokenizer to split sentences. \n",
    "# but let's try it the lazy way to start\n",
    "df = df['para_str'].str.split(\"[.!?]+\", expand=True)\\\n",
    "    .stack().to_frame().rename(columns={0:'sent_str'})\n",
    "df.index.names = ohco[0:4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 239,
   "metadata": {},
   "outputs": [],
   "source": [
    "# drop 0-length strings (usually at end of paragraph)\n",
    "df = df[df['sent_str'].str.len() > 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 240,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>sent_str</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>speech_id</th>\n",
       "      <th>speaker</th>\n",
       "      <th>para_id</th>\n",
       "      <th>sent_id</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"5\" valign=\"top\">0</th>\n",
       "      <th rowspan=\"5\" valign=\"top\">CLINTON</th>\n",
       "      <th rowspan=\"5\" valign=\"top\">0</th>\n",
       "      <th>0</th>\n",
       "      <td>Wow</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Thank you</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Thank you all</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Thank you</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>I am really delighted to be here on the first...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                            sent_str\n",
       "speech_id speaker para_id sent_id                                                   \n",
       "0         CLINTON 0       0                                                      Wow\n",
       "                          1                                                Thank you\n",
       "                          2                                            Thank you all\n",
       "                          3                                                Thank you\n",
       "                          4         I am really delighted to be here on the first..."
      ]
     },
     "execution_count": 240,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 241,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fourth ohco level - tokens\n",
    "import nltk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 242,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/maxwell/opt/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:1: DeprecationWarning: The default dtype for empty Series will be 'object' instead of 'float64' in a future version. Specify a dtype explicitly to silence this warning.\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n"
     ]
    }
   ],
   "source": [
    "token = df['sent_str'].apply(lambda x: pd.Series(nltk.pos_tag(nltk.WhitespaceTokenizer().tokenize(x))))\\\n",
    "    .stack().to_frame()\\\n",
    "    .rename(columns={0:'pos_tuple'})\n",
    "token['pos'] = token.pos_tuple.apply(lambda x: x[1])\n",
    "token['token_str'] = token.pos_tuple.apply(lambda x: x[0])\n",
    "token = token.drop('pos_tuple', 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 243,
   "metadata": {},
   "outputs": [],
   "source": [
    "token.index.names = ohco # ok, all done"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 244,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>pos</th>\n",
       "      <th>token_str</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>speech_id</th>\n",
       "      <th>speaker</th>\n",
       "      <th>para_id</th>\n",
       "      <th>sent_id</th>\n",
       "      <th>token_id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"5\" valign=\"top\">0</th>\n",
       "      <th rowspan=\"5\" valign=\"top\">CLINTON</th>\n",
       "      <th rowspan=\"5\" valign=\"top\">0</th>\n",
       "      <th>0</th>\n",
       "      <th>0</th>\n",
       "      <td>NN</td>\n",
       "      <td>Wow</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">1</th>\n",
       "      <th>0</th>\n",
       "      <td>NN</td>\n",
       "      <td>Thank</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>PRP</td>\n",
       "      <td>you</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">2</th>\n",
       "      <th>0</th>\n",
       "      <td>NNP</td>\n",
       "      <td>Thank</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>PRP</td>\n",
       "      <td>you</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            pos token_str\n",
       "speech_id speaker para_id sent_id token_id               \n",
       "0         CLINTON 0       0       0          NN       Wow\n",
       "                          1       0          NN     Thank\n",
       "                                  1         PRP       you\n",
       "                          2       0         NNP     Thank\n",
       "                                  1         PRP       you"
      ]
     },
     "execution_count": 244,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "token.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 245,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lowercase, remove non-word characters\n",
    "token['term_str'] = token['token_str'].str.lower().str.replace('[\\W_]', '')\n",
    "# drop words which consist entirely of non-word characters\n",
    "token = token[token.term_str!=''].sort_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 246,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Checkpoint\n",
    "token.to_parquet('data/token.parquet')\n",
    "library.to_parquet('data/library.parquet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 247,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load from checkpoint\n",
    "if 'token' not in locals():\n",
    "    token = pd.read_parquet('data/token.parquet')\n",
    "if 'library' not in locals():\n",
    "    library = pd.read_parquet('data/library.parquet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 248,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create vocab table\n",
    "# \n",
    "vocab = token.term_str.value_counts().to_frame().rename(columns={'index':'term_str', 'term_str':'n'})\\\n",
    "    .sort_index().reset_index().rename(columns={'index':'term_str'})\n",
    "vocab.index.name = 'term_id'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 249,
   "metadata": {},
   "outputs": [],
   "source": [
    "# add stopwords\n",
    "vocab['stop'] = 0\n",
    "vocab.loc[vocab['term_str'].isin(nltk.corpus.stopwords.words('english')),'stop'] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 250,
   "metadata": {},
   "outputs": [],
   "source": [
    "# (optional) add stems\n",
    "#from nltk.stem.porter import PorterStemmer\n",
    "#stemmer = PorterStemmer()\n",
    "#vocab['p_stem'] = vocab.term_str.apply(stemmer.stem)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 251,
   "metadata": {},
   "outputs": [],
   "source": [
    "# add term rank \n",
    "if 'term_rank' not in vocab.columns:\n",
    "    vocab = vocab.sort_values('n', ascending=False).reset_index()\n",
    "    vocab.index.name = 'term_rank'\n",
    "    vocab = vocab.reset_index().set_index('term_id')\n",
    "    vocab['term_rank'] = vocab['term_rank'] + 1 # start with 1 instead of 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 252,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>term_rank</th>\n",
       "      <th>term_str</th>\n",
       "      <th>n</th>\n",
       "      <th>stop</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>term_id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>10832</th>\n",
       "      <td>1</td>\n",
       "      <td>the</td>\n",
       "      <td>13552</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11006</th>\n",
       "      <td>2</td>\n",
       "      <td>to</td>\n",
       "      <td>12704</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>782</th>\n",
       "      <td>3</td>\n",
       "      <td>and</td>\n",
       "      <td>12178</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5499</th>\n",
       "      <td>4</td>\n",
       "      <td>i</td>\n",
       "      <td>7337</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7517</th>\n",
       "      <td>5</td>\n",
       "      <td>of</td>\n",
       "      <td>6918</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         term_rank term_str      n  stop\n",
       "term_id                                 \n",
       "10832            1      the  13552     1\n",
       "11006            2       to  12704     1\n",
       "782              3      and  12178     1\n",
       "5499             4        i   7337     1\n",
       "7517             5       of   6918     1"
      ]
     },
     "execution_count": 252,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vocab.sort_values('n', ascending=False).head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 253,
   "metadata": {},
   "outputs": [],
   "source": [
    "# add term id back to token table, for easy joining\n",
    "token['term_id'] = token.term_str.map(vocab.reset_index().set_index('term_str').term_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 254,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Checkpoint\n",
    "vocab.to_parquet('data/vocab.parquet')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create DT matrices \n",
    "(Document-Term matrix, using Bag of Words and TF-IDF)\n",
    "\n",
    "One each for Trump and Clinton"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 267,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load from checkpoint\n",
    "if 'vocab' not in locals():\n",
    "    vocab = pd.read_parquet('data/vocab.parquet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 268,
   "metadata": {},
   "outputs": [],
   "source": [
    "bag = ohco[:1] # bag size = 1 speech"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 269,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 100 speeches, take 20% for test set\n",
    "test_ids = np.random.choice(token.reset_index().speech_id.unique(),size=20,replace=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 270,
   "metadata": {},
   "outputs": [],
   "source": [
    "token = token.reset_index().set_index('speech_id')\n",
    "test_token = token.loc[test_ids]\n",
    "train_token = token.loc[~token.index.isin(test_ids)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 271,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split into Trump/Clinton\n",
    "clinton_train = train_token.query('speaker==\"CLINTON\"')\n",
    "trump_train = train_token.query('speaker==\"TRUMP\"')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 322,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.45121951219512196, 0.5487804878048781]"
      ]
     },
     "execution_count": 322,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clinton_count = len(clinton_train.index.unique())\n",
    "trump_count = len(trump_train.index.unique())\n",
    "total_count = clinton_count + trump_count\n",
    "priors = [clinton_count/total_count,trump_count/total_count]\n",
    "priors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 350,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_vocab(token, a=1):\n",
    "    vocab = token.term_str.value_counts().to_frame().rename(columns={'index':'term_str', 'term_str':'n'})\\\n",
    "    .sort_index().reset_index().rename(columns={'index':'term_str'})\n",
    "    vocab.index.name = 'term_id'\n",
    "    vocab['stop'] = 0\n",
    "    vocab.loc[vocab['term_str'].isin(nltk.corpus.stopwords.words('english')),'stop'] = 1\n",
    "    if 'term_rank' not in vocab.columns:\n",
    "        vocab = vocab.sort_values('n', ascending=False).reset_index()\n",
    "        vocab.index.name = 'term_rank'\n",
    "        vocab = vocab.reset_index().set_index('term_id')\n",
    "        vocab['term_rank'] = vocab['term_rank'] + 1 # start with 1 instead of 0\n",
    "    token['term_id'] = token.term_str.map(vocab.reset_index().set_index('term_str').term_id)\n",
    "    BOW = token.groupby(bag+['term_id']).term_id.count()\\\n",
    "    .to_frame().rename(columns={'term_id':'n'})\n",
    "    DTCM = BOW['n'].unstack().fillna(0).astype('int')\n",
    "    # Term frequency - normalized\n",
    "    TF = (DTCM.T / DTCM.T.sum()).T\n",
    "    DF = DTCM[DTCM > 0].count()\n",
    "    freq=TF.sum().reset_index()\n",
    "    vocab['freq'] = freq[0]\n",
    "    tf = vocab.freq # term frequency (normalized)\n",
    "    N = vocab.freq.sum() # sum of all term frequencies in this class\n",
    "    V = vocab.shape[0] # vocab size\n",
    "    # https://stackoverflow.com/questions/3704570/in-python-small-floats-tending-to-zero\n",
    "    # https://nlp.stanford.edu/IR-book/html/htmledition/naive-bayes-text-classification-1.html\n",
    "    # using the log likelihood for these reasons\n",
    "    vocab['likelihood'] = np.log((tf+a) / (N+ a*V))\n",
    "    vocab.sort_values('likelihood',ascending=False)\n",
    "    return vocab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 351,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/maxwell/opt/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:12: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  if sys.path[0] == '':\n"
     ]
    }
   ],
   "source": [
    "vocab_c = create_vocab(clinton_train).reset_index().set_index('term_str')\n",
    "vocab_t = create_vocab(trump_train).reset_index().set_index('term_str')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 352,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>term_id</th>\n",
       "      <th>term_rank</th>\n",
       "      <th>n</th>\n",
       "      <th>stop</th>\n",
       "      <th>freq</th>\n",
       "      <th>likelihood</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>term_str</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>to</th>\n",
       "      <td>6228</td>\n",
       "      <td>1</td>\n",
       "      <td>4342</td>\n",
       "      <td>1</td>\n",
       "      <td>1.603061</td>\n",
       "      <td>-7.880558</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>the</th>\n",
       "      <td>6121</td>\n",
       "      <td>2</td>\n",
       "      <td>4189</td>\n",
       "      <td>1</td>\n",
       "      <td>1.560112</td>\n",
       "      <td>-7.897194</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>and</th>\n",
       "      <td>449</td>\n",
       "      <td>3</td>\n",
       "      <td>3750</td>\n",
       "      <td>1</td>\n",
       "      <td>1.355956</td>\n",
       "      <td>-7.980299</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>i</th>\n",
       "      <td>3098</td>\n",
       "      <td>4</td>\n",
       "      <td>2722</td>\n",
       "      <td>1</td>\n",
       "      <td>1.126600</td>\n",
       "      <td>-8.082721</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>of</th>\n",
       "      <td>4227</td>\n",
       "      <td>5</td>\n",
       "      <td>2062</td>\n",
       "      <td>1</td>\n",
       "      <td>0.767632</td>\n",
       "      <td>-8.267605</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>piecing</th>\n",
       "      <td>4545</td>\n",
       "      <td>6881</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000671</td>\n",
       "      <td>-8.836575</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>piled</th>\n",
       "      <td>4546</td>\n",
       "      <td>6882</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000194</td>\n",
       "      <td>-8.837052</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>eager</th>\n",
       "      <td>2049</td>\n",
       "      <td>6883</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000194</td>\n",
       "      <td>-8.837052</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>pinata</th>\n",
       "      <td>4550</td>\n",
       "      <td>6884</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000379</td>\n",
       "      <td>-8.836867</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>journalists</th>\n",
       "      <td>3442</td>\n",
       "      <td>6885</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000379</td>\n",
       "      <td>-8.836867</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>6885 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             term_id  term_rank     n  stop      freq  likelihood\n",
       "term_str                                                         \n",
       "to              6228          1  4342     1  1.603061   -7.880558\n",
       "the             6121          2  4189     1  1.560112   -7.897194\n",
       "and              449          3  3750     1  1.355956   -7.980299\n",
       "i               3098          4  2722     1  1.126600   -8.082721\n",
       "of              4227          5  2062     1  0.767632   -8.267605\n",
       "...              ...        ...   ...   ...       ...         ...\n",
       "piecing         4545       6881     1     0  0.000671   -8.836575\n",
       "piled           4546       6882     1     0  0.000194   -8.837052\n",
       "eager           2049       6883     1     0  0.000194   -8.837052\n",
       "pinata          4550       6884     1     0  0.000379   -8.836867\n",
       "journalists     3442       6885     1     0  0.000379   -8.836867\n",
       "\n",
       "[6885 rows x 6 columns]"
      ]
     },
     "execution_count": 352,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vocab_c"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 353,
   "metadata": {},
   "outputs": [],
   "source": [
    "def NB_classifier(token_test, class1_vocab, class2_vocab, priors=[.5,.5]):\n",
    "    d = {'speech_id': token_test.index.unique(), 'true_value': \"\", 'prediction': \"\"}\n",
    "    results = pd.DataFrame(d).set_index('speech_id')\n",
    "    \n",
    "    for i in results.index:\n",
    "        results['true_value'].loc[i] = test_token.at[i,'speaker'][0]\n",
    "        \n",
    "        speech = token_test.loc[i]\n",
    "        \n",
    "        speech = speech.merge(class1_vocab['likelihood'], how='inner', on=\"term_str\")\\\n",
    "        .rename(columns={'likelihood': 'class1_prob'})\n",
    "        speech = speech.merge(class2_vocab['likelihood'], how='inner', on=\"term_str\")\\\n",
    "        .rename(columns={'likelihood': 'class2_prob'})\n",
    "        \n",
    "        predict = pd.DataFrame(speech[['class1_prob','class2_prob']].sum())\n",
    "        logpriors = np.log(priors)\n",
    "        predict[0] = predict[0] + logpriors\n",
    "        predict[0] = predict.sort_values(by=0, ascending=False)\n",
    "        classification = predict.index[0]\n",
    "        \n",
    "        results['prediction'].loc[i] = classification\n",
    "        \n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 355,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>true_value</th>\n",
       "      <th>prediction</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>speech_id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>CLINTON</td>\n",
       "      <td>class1_prob</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>TRUMP</td>\n",
       "      <td>class1_prob</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>144</th>\n",
       "      <td>CLINTON</td>\n",
       "      <td>class1_prob</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>CLINTON</td>\n",
       "      <td>class1_prob</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>140</th>\n",
       "      <td>TRUMP</td>\n",
       "      <td>class1_prob</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>TRUMP</td>\n",
       "      <td>class1_prob</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>123</th>\n",
       "      <td>TRUMP</td>\n",
       "      <td>class1_prob</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>147</th>\n",
       "      <td>CLINTON</td>\n",
       "      <td>class1_prob</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>154</th>\n",
       "      <td>CLINTON</td>\n",
       "      <td>class1_prob</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>155</th>\n",
       "      <td>CLINTON</td>\n",
       "      <td>class1_prob</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>CLINTON</td>\n",
       "      <td>class1_prob</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>118</th>\n",
       "      <td>TRUMP</td>\n",
       "      <td>class1_prob</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>CLINTON</td>\n",
       "      <td>class1_prob</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>CLINTON</td>\n",
       "      <td>class1_prob</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48</th>\n",
       "      <td>TRUMP</td>\n",
       "      <td>class1_prob</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>148</th>\n",
       "      <td>CLINTON</td>\n",
       "      <td>class1_prob</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>CLINTON</td>\n",
       "      <td>class1_prob</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>TRUMP</td>\n",
       "      <td>class1_prob</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>CLINTON</td>\n",
       "      <td>class1_prob</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>133</th>\n",
       "      <td>TRUMP</td>\n",
       "      <td>class1_prob</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          true_value   prediction\n",
       "speech_id                        \n",
       "12           CLINTON  class1_prob\n",
       "46             TRUMP  class1_prob\n",
       "144          CLINTON  class1_prob\n",
       "1            CLINTON  class1_prob\n",
       "140            TRUMP  class1_prob\n",
       "34             TRUMP  class1_prob\n",
       "123            TRUMP  class1_prob\n",
       "147          CLINTON  class1_prob\n",
       "154          CLINTON  class1_prob\n",
       "155          CLINTON  class1_prob\n",
       "7            CLINTON  class1_prob\n",
       "118            TRUMP  class1_prob\n",
       "26           CLINTON  class1_prob\n",
       "11           CLINTON  class1_prob\n",
       "48             TRUMP  class1_prob\n",
       "148          CLINTON  class1_prob\n",
       "6            CLINTON  class1_prob\n",
       "44             TRUMP  class1_prob\n",
       "17           CLINTON  class1_prob\n",
       "133            TRUMP  class1_prob"
      ]
     },
     "execution_count": 355,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# class 1 is clinton, class 2 is trump\n",
    "\n",
    "NB_classifier(test_token,vocab_c,vocab_t,priors=priors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
