{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from glob import glob\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "ohco = ['speech_id','speaker','para_id','sent_id','token_id']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_json('data/ucsb_speeches_2016.json')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>link</th>\n",
       "      <th>title</th>\n",
       "      <th>date</th>\n",
       "      <th>person</th>\n",
       "      <th>transcript</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>/documents/remarks-town-hall-meeting-portsmout...</td>\n",
       "      <td>Remarks at a Town Hall Meeting in Portsmouth, ...</td>\n",
       "      <td>2015-12-29 00:00:00+00:00</td>\n",
       "      <td>Hillary Clinton</td>\n",
       "      <td>\\nCLINTON: Wow. Thank you. Thank you all. Than...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>/documents/remarks-the-university-minnesota-mi...</td>\n",
       "      <td>Remarks at the University of Minnesota in Minn...</td>\n",
       "      <td>2015-12-15 00:00:00+00:00</td>\n",
       "      <td>Hillary Clinton</td>\n",
       "      <td>\\nThank you. Thank you all very much. Thank yo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>/documents/interview-with-george-stephanopoulo...</td>\n",
       "      <td>Interview with George Stephanopoulos of ABC Ne...</td>\n",
       "      <td>2015-12-06 00:00:00+00:00</td>\n",
       "      <td>Hillary Clinton</td>\n",
       "      <td>\\nSTEPHANOPOULOS: And we'll hear more on that ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>/documents/interview-with-charlie-rose</td>\n",
       "      <td>Interview with Charlie Rose</td>\n",
       "      <td>2015-12-01 00:00:00+00:00</td>\n",
       "      <td>Hillary Clinton</td>\n",
       "      <td>\\nROSE: She is a former first lady, a former s...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>/documents/remarks-and-question-and-answer-ses...</td>\n",
       "      <td>Remarks and a Question and Answer Session at t...</td>\n",
       "      <td>2015-11-19 00:00:00+00:00</td>\n",
       "      <td>Hillary Clinton</td>\n",
       "      <td>\\nCLINTON: Thank you. Thank you very much. [ap...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                link  \\\n",
       "0  /documents/remarks-town-hall-meeting-portsmout...   \n",
       "1  /documents/remarks-the-university-minnesota-mi...   \n",
       "2  /documents/interview-with-george-stephanopoulo...   \n",
       "3             /documents/interview-with-charlie-rose   \n",
       "4  /documents/remarks-and-question-and-answer-ses...   \n",
       "\n",
       "                                               title  \\\n",
       "0  Remarks at a Town Hall Meeting in Portsmouth, ...   \n",
       "1  Remarks at the University of Minnesota in Minn...   \n",
       "2  Interview with George Stephanopoulos of ABC Ne...   \n",
       "3                        Interview with Charlie Rose   \n",
       "4  Remarks and a Question and Answer Session at t...   \n",
       "\n",
       "                       date           person  \\\n",
       "0 2015-12-29 00:00:00+00:00  Hillary Clinton   \n",
       "1 2015-12-15 00:00:00+00:00  Hillary Clinton   \n",
       "2 2015-12-06 00:00:00+00:00  Hillary Clinton   \n",
       "3 2015-12-01 00:00:00+00:00  Hillary Clinton   \n",
       "4 2015-11-19 00:00:00+00:00  Hillary Clinton   \n",
       "\n",
       "                                          transcript  \n",
       "0  \\nCLINTON: Wow. Thank you. Thank you all. Than...  \n",
       "1  \\nThank you. Thank you all very much. Thank yo...  \n",
       "2  \\nSTEPHANOPOULOS: And we'll hear more on that ...  \n",
       "3  \\nROSE: She is a former first lady, a former s...  \n",
       "4  \\nCLINTON: Thank you. Thank you very much. [ap...  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.index.name = 'speech_id'\n",
    "library = df[['link','title','date','person']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# first OHCO level - split out speakers, using e.g. \"CLINTON:\"\n",
    "# set default speaker for each speech - we'll set the specific ones later.\n",
    "df['speaker'] = [x[1] for x in df['person'].str.upper().str.rsplit(' ',1)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.reset_index().set_index(['speech_id','speaker'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# second OHCO level - split out paragraphs, using \"\\n\" as the separator (for these transcripts). \n",
    "# Remove initial/trailing whitespace, including \\n\n",
    "df = df['transcript'].str.strip().str.split(\"\\n\", expand=True)\\\n",
    "    .stack().to_frame().rename(columns={0:'para_str'})\n",
    "df.index.names = ohco[0:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.reset_index().set_index(['speech_id','para_id'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# whenever a paragraph starts with a caps name e.g. CLINTON:\n",
    "# use that as the speaker until the next caps name\n",
    "df['speaker'] = df['para_str'].str.extract(r'([A-Z]+)(:)')[0].ffill()\n",
    "# remove the non-Trump/Clinton speakers\n",
    "df = df[df['speaker'].isin(['TRUMP','CLINTON'])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.reset_index().set_index(ohco[0:3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# remove the caps names\n",
    "df['para_str'] = df['para_str'].str.replace(r'[A-Z]+: ','')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# third ohco level - sentence\n",
    "\n",
    "# Alvarado used NLTK sentence tokenizer to split sentences. \n",
    "# but let's try it the lazy way to start\n",
    "df = df['para_str'].str.split(\"[.!?]+\", expand=True)\\\n",
    "    .stack().to_frame().rename(columns={0:'sent_str'})\n",
    "df.index.names = ohco[0:4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# drop 0-length strings (usually at end of paragraph)\n",
    "df = df[df['sent_str'].str.len() > 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>sent_str</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>speech_id</th>\n",
       "      <th>speaker</th>\n",
       "      <th>para_id</th>\n",
       "      <th>sent_id</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"5\" valign=\"top\">0</th>\n",
       "      <th rowspan=\"5\" valign=\"top\">CLINTON</th>\n",
       "      <th rowspan=\"5\" valign=\"top\">0</th>\n",
       "      <th>0</th>\n",
       "      <td>Wow</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Thank you</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Thank you all</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Thank you</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>I am really delighted to be here on the first...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                            sent_str\n",
       "speech_id speaker para_id sent_id                                                   \n",
       "0         CLINTON 0       0                                                      Wow\n",
       "                          1                                                Thank you\n",
       "                          2                                            Thank you all\n",
       "                          3                                                Thank you\n",
       "                          4         I am really delighted to be here on the first..."
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fourth ohco level - tokens\n",
    "import nltk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-17-1da6e9b0a34b>:1: DeprecationWarning: The default dtype for empty Series will be 'object' instead of 'float64' in a future version. Specify a dtype explicitly to silence this warning.\n",
      "  token = df['sent_str'].apply(lambda x: pd.Series(nltk.pos_tag(nltk.WhitespaceTokenizer().tokenize(x))))\\\n"
     ]
    }
   ],
   "source": [
    "token = df['sent_str'].apply(lambda x: pd.Series(nltk.pos_tag(nltk.WhitespaceTokenizer().tokenize(x))))\\\n",
    "    .stack().to_frame()\\\n",
    "    .rename(columns={0:'pos_tuple'})\n",
    "token['pos'] = token.pos_tuple.apply(lambda x: x[1])\n",
    "token['token_str'] = token.pos_tuple.apply(lambda x: x[0])\n",
    "token = token.drop('pos_tuple', 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "token.index.names = ohco # ok, all done"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>pos</th>\n",
       "      <th>token_str</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>speech_id</th>\n",
       "      <th>speaker</th>\n",
       "      <th>para_id</th>\n",
       "      <th>sent_id</th>\n",
       "      <th>token_id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"5\" valign=\"top\">0</th>\n",
       "      <th rowspan=\"5\" valign=\"top\">CLINTON</th>\n",
       "      <th rowspan=\"5\" valign=\"top\">0</th>\n",
       "      <th>0</th>\n",
       "      <th>0</th>\n",
       "      <td>NN</td>\n",
       "      <td>Wow</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">1</th>\n",
       "      <th>0</th>\n",
       "      <td>NN</td>\n",
       "      <td>Thank</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>PRP</td>\n",
       "      <td>you</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">2</th>\n",
       "      <th>0</th>\n",
       "      <td>NNP</td>\n",
       "      <td>Thank</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>PRP</td>\n",
       "      <td>you</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            pos token_str\n",
       "speech_id speaker para_id sent_id token_id               \n",
       "0         CLINTON 0       0       0          NN       Wow\n",
       "                          1       0          NN     Thank\n",
       "                                  1         PRP       you\n",
       "                          2       0         NNP     Thank\n",
       "                                  1         PRP       you"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "token.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lowercase, remove non-word characters\n",
    "token['term_str'] = token['token_str'].str.lower().str.replace('[\\W_]', '')\n",
    "# drop words which consist entirely of non-word characters\n",
    "token = token[token.term_str!=''].sort_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Checkpoint\n",
    "token.to_parquet('data/token.parquet')\n",
    "library.to_parquet('data/library.parquet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load from checkpoint\n",
    "if 'token' not in locals():\n",
    "    token = pd.read_parquet('data/token.parquet')\n",
    "if 'library' not in locals():\n",
    "    library = pd.read_parquet('data/library.parquet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create vocab table\n",
    "# \n",
    "vocab = token.term_str.value_counts().to_frame().rename(columns={'index':'term_str', 'term_str':'n'})\\\n",
    "    .sort_index().reset_index().rename(columns={'index':'term_str'})\n",
    "vocab.index.name = 'term_id'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# add stopwords\n",
    "vocab['stop'] = 0\n",
    "vocab.loc[vocab['term_str'].isin(nltk.corpus.stopwords.words('english')),'stop'] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# (optional) add stems\n",
    "#from nltk.stem.porter import PorterStemmer\n",
    "#stemmer = PorterStemmer()\n",
    "#vocab['p_stem'] = vocab.term_str.apply(stemmer.stem)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# add term rank \n",
    "if 'term_rank' not in vocab.columns:\n",
    "    vocab = vocab.sort_values('n', ascending=False).reset_index()\n",
    "    vocab.index.name = 'term_rank'\n",
    "    vocab = vocab.reset_index().set_index('term_id')\n",
    "    vocab['term_rank'] = vocab['term_rank'] + 1 # start with 1 instead of 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>term_rank</th>\n",
       "      <th>term_str</th>\n",
       "      <th>n</th>\n",
       "      <th>stop</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>term_id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>10832</th>\n",
       "      <td>1</td>\n",
       "      <td>the</td>\n",
       "      <td>13552</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11006</th>\n",
       "      <td>2</td>\n",
       "      <td>to</td>\n",
       "      <td>12704</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>782</th>\n",
       "      <td>3</td>\n",
       "      <td>and</td>\n",
       "      <td>12178</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5499</th>\n",
       "      <td>4</td>\n",
       "      <td>i</td>\n",
       "      <td>7337</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7517</th>\n",
       "      <td>5</td>\n",
       "      <td>of</td>\n",
       "      <td>6918</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         term_rank term_str      n  stop\n",
       "term_id                                 \n",
       "10832            1      the  13552     1\n",
       "11006            2       to  12704     1\n",
       "782              3      and  12178     1\n",
       "5499             4        i   7337     1\n",
       "7517             5       of   6918     1"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vocab.sort_values('n', ascending=False).head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# add term id back to token table, for easy joining\n",
    "token['term_id'] = token.term_str.map(vocab.reset_index().set_index('term_str').term_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Checkpoint\n",
    "vocab.to_parquet('data/vocab.parquet')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create DT matrices \n",
    "(Document-Term matrix, using Bag of Words and TF-IDF)\n",
    "\n",
    "One each for Trump and Clinton"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load from checkpoint\n",
    "if 'vocab' not in locals():\n",
    "    vocab = pd.read_parquet('data/vocab.parquet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "bag = ohco[:1] # bag size = 1 speech"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split into Trump/Clinton\n",
    "clinton = token.query('speaker==\"CLINTON\"')\n",
    "trump = token.query('speaker==\"TRUMP\"')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "BOW_c = clinton.groupby(bag+['term_id']).term_id.count()\\\n",
    "    .to_frame().rename(columns={'term_id':'n'})\n",
    "BOW_t = trump.groupby(bag+['term_id']).term_id.count()\\\n",
    "    .to_frame().rename(columns={'term_id':'n'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Document-Term Matrices\n",
    "DTCM_c = BOW_c['n'].unstack().fillna(0).astype('int')\n",
    "DTCM_t = BOW_t['n'].unstack().fillna(0).astype('int')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Term frequency - normalized\n",
    "TF_c = (DTCM_c.T / DTCM_c.T.sum()).T\n",
    "TF_t = (DTCM_t.T / DTCM_t.T.sum()).T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Document frequency\n",
    "DF_c = DTCM_c[DTCM_c > 0].count()\n",
    "DF_t = DTCM_t[DTCM_t > 0].count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create vocab tables for Clinton / Trump\n",
    "# \n",
    "vocab_c = clinton.term_str.value_counts().to_frame().rename(columns={'index':'term_str', 'term_str':'n'})\\\n",
    "    .sort_index().reset_index().rename(columns={'index':'term_str'})\n",
    "vocab_c.index.name = 'term_id'\n",
    "\n",
    "vocab_t = trump.term_str.value_counts().to_frame().rename(columns={'index':'term_str', 'term_str':'n'})\\\n",
    "    .sort_index().reset_index().rename(columns={'index':'term_str'})\n",
    "vocab_t.index.name = 'term_id'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "# add stopwords\n",
    "vocab_c['stop'] = 0\n",
    "vocab_c.loc[vocab_c['term_str'].isin(nltk.corpus.stopwords.words('english')),'stop'] = 1\n",
    "\n",
    "vocab_t['stop'] = 0\n",
    "vocab_t.loc[vocab_t['term_str'].isin(nltk.corpus.stopwords.words('english')),'stop'] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab_c['freq'] = TF_c.sum()\n",
    "vocab_t['freq'] = TF_t.sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf = vocab_c.freq # term frequency (normalized)\n",
    "a = 1 # Laplace smoothing\n",
    "N = vocab_c.freq.sum() # sum of all term frequencies in this class\n",
    "V = vocab_c.shape[0] # vocab size\n",
    "vocab_c['likelihood'] = (tf+a) / (N+ a*V)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf = vocab_t.freq # term frequency (normalized)\n",
    "a = 1 # Laplace smoothing\n",
    "N = vocab_t.freq.sum() # sum of all term frequencies in this class\n",
    "V = vocab_t.shape[0] # vocab size\n",
    "vocab_t['likelihood'] = (tf+a) / (N+ a*V)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>term_str</th>\n",
       "      <th>n</th>\n",
       "      <th>stop</th>\n",
       "      <th>freq</th>\n",
       "      <th>likelihood</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>term_id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>782</th>\n",
       "      <td>attorney</td>\n",
       "      <td>12</td>\n",
       "      <td>0</td>\n",
       "      <td>1.934847</td>\n",
       "      <td>0.000335</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7517</th>\n",
       "      <td>stupidity</td>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "      <td>1.142693</td>\n",
       "      <td>0.000245</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>366</th>\n",
       "      <td>activity</td>\n",
       "      <td>10</td>\n",
       "      <td>0</td>\n",
       "      <td>0.970873</td>\n",
       "      <td>0.000225</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5616</th>\n",
       "      <td>pad</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0.883623</td>\n",
       "      <td>0.000215</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5499</th>\n",
       "      <td>opponents</td>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "      <td>0.810991</td>\n",
       "      <td>0.000207</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8694</th>\n",
       "      <td>yesyes</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8709</th>\n",
       "      <td>young</td>\n",
       "      <td>87</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8710</th>\n",
       "      <td>younger</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8716</th>\n",
       "      <td>yourself</td>\n",
       "      <td>17</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8722</th>\n",
       "      <td>z</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8728 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          term_str   n  stop      freq  likelihood\n",
       "term_id                                           \n",
       "782       attorney  12     0  1.934847    0.000335\n",
       "7517     stupidity   8     0  1.142693    0.000245\n",
       "366       activity  10     0  0.970873    0.000225\n",
       "5616           pad   2     0  0.883623    0.000215\n",
       "5499     opponents   8     0  0.810991    0.000207\n",
       "...            ...  ..   ...       ...         ...\n",
       "8694        yesyes   1     0       NaN         NaN\n",
       "8709         young  87     0       NaN         NaN\n",
       "8710       younger   2     0       NaN         NaN\n",
       "8716      yourself  17     1       NaN         NaN\n",
       "8722             z   1     0       NaN         NaN\n",
       "\n",
       "[8728 rows x 5 columns]"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vocab_t.sort_values('likelihood',ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pymc3 as pm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
